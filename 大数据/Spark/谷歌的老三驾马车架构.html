<html>
<head>
  <title>谷歌的老三驾马车架构:</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/603932 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 12pt;
    }
  </style>
</head>
<body>
<a name="8112"/>
<h1>谷歌的老三驾马车架构:</h1>
<div>
<table bgcolor="#D4DDE5" border="0">
<tr><td><b>创建时间：</b></td><td><i>2021/4/27 11:57</i></td></tr>
<tr><td><b>更新时间：</b></td><td><i>2021/4/27 12:01</i></td></tr>
</table>
</div>
<br/>

<div>
<span><div><br/></div><div><br/></div><div>谷歌的老三驾马车架构: </div><div><img src="谷歌的老三驾马车架构_files/02google老的三驾马车作用.png" type="image/png" data-filename="02google老的三驾马车作用.png" width="855"/></div><div><br/></div><div><br/></div><div>大数据生态图: </div><div><img src="谷歌的老三驾马车架构_files/01大数据生态图.png" type="image/png" data-filename="01大数据生态图.png"/></div><div>===================================================================</div><div><br/></div><div>Spark安装</div><div>    第一步安装scala</div><div>        解压：~]$ tar -zxvf soft/scala-2.11.8.tgz</div><div>        重命名：~]$ mv scala-2.11.8 scala</div><div>        配置到环境变量：</div><div>        export SCALA_HOME=/home/bigdata/app/scala</div><div>        export PATH=$PATH:$SCALA_HOME/bin</div><div>    单机</div><div>        解压重命名spark安装包到/home/bigdata/app</div><div>        配置环境变量：</div><div>            export SPARK_HOME=/home/bigdata/app/spark</div><div>            export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin</div><div>        测试是否已经安装好？</div><div>            简单的运行一个spark小程序</div><div>            bin/spark-shell</div><div>            scala&gt; sc.textFile(&quot;/home/bigdata/app/data/hello&quot;).flatMap(_.split(&quot; &quot;)).map((_, 1)).reduceByKey(_+_).collect.foreach(println)</div><div>=========================================================================</div><div>    完全分布式的配置</div><div>        修改spark-env.sh</div><div>            1、cd /home/bigdata/app/spark/conf</div><div>            2、cp spark-env.sh.template spark-env.sh</div><div>            3、vi spark-env.sh</div><div>                export JAVA_HOME=/opt/jdk</div><div>                export SCALA_HOME=/home/bigdata/app/scala</div><div>                #主节点的master的ip地址或者hostname</div><div>                export SPARK_MASTER_HOST=bigdata01</div><div>                #7077的作业就相当于hdfs中9000,切忌不是50070---&gt;8080</div><div>                export SPARK_MASTER_PORT=7077</div><div>                #从节点中每一个worker的cpu core的个数</div><div>                export SPARK_WORKER_CORES=1</div><div>                #在slaves配置中配置的每一台机器上面启动的worker的个数</div><div>                export SPARK_WORKER_INSTANCES=1</div><div>                #每一个worker的内存资源，配置不要超过当前机器的内存资源</div><div>                #建议不要低于500m</div><div>                export SPARK_WORKER_MEMORY=1g</div><div>                export HADOOP_CONF_DIR=/home/bigdata/app/hadoop/etc/hadoop</div><div>        修改slaves配置文件</div><div>            添加两行记录</div><div>            bigdata02</div><div>            bigdata03</div><div>        部署到bigdata02和bigdata03这两台机器上(这两台机器需要提前安装scala)</div><div>            scp -r /home/bigdata/app/scala bigdata@bigdata02:/home/bigdata/app</div><div>            scp -r /home/bigdata/app/scala bigdata@bigdata03:/home/bigdata/app</div><div>            ----</div><div>            scp -r /home/bigdata/app/spark bigdata@bigdata02:/home/bigdata/app</div><div>            scp -r /home/bigdata/app/spark bigdata@bigdata03:/home/bigdata/app</div><div>            ---在bigdata02和bigdata03上加载好环境变量,需要source生效</div><div>            scp ~/.bash_profile bigdata@bigdata02:/home/bigdata</div><div>            scp ~/.bash_profile bigdata@bigdata03:/home/bigdata</div><div>    启动</div><div>        修改事宜</div><div>            为了避免和hadoop中的start/stop-all.sh脚本发生冲突，将spark/sbin/start/stop-all.sh重命名</div><div>            sbin]# mv start-all.sh start-all-spark.sh</div><div>            sbin]# mv stop-all.sh stop-all-spark.sh</div><div>        启动</div><div>            sbin/start-all-spark.sh</div><div>            会在我们配置的主节点master上启动一个进程Master</div><div>            会在我们配置的从节点bigdata02上启动一个进程Worker</div><div>            会在我们配置的从节点bigdata03上启动一个进程Worker</div><div>        简单的验证</div><div>            启动spark-shell</div><div>            bin/spark-shell</div><div>            scala&gt; sc.textFile(&quot;<a href="hdfs://ns1/data/hello">hdfs://ns1/data/hello&quot;).flatMap(_.split</a>(&quot; &quot;)).map((_, 1)).reduceByKey(_+_).collect.foreach(println)</div><div>            我们发现spark非常快速的执行了这个程序，计算出我们想要的结果</div><div>            </div><div>        一个端口:8080/4040</div><div>            8080--&gt;spark集群的访问端口，类似于hadoop中的50070和8080的综合</div><div>            4040--&gt;sparkUI的访问地址</div><div>            7077--&gt;hadoop中的9000端口</div><div>=====================================================================</div><div>    基于Zookeeper的HA的配置</div><div>        最好在集群停止的时候来做</div><div>        第一件事</div><div>            注释掉spark-env.sh中两行内容</div><div>                #export SPARK_MASTER_IP=bigdata01</div><div>                #export SPARK_MASTER_PORT=7077</div><div>        第二件事</div><div>            在spark-env.sh中加一行内容</div><div>                export SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=bigdata01:2181,bigdata02:2181,bigdata03:2181 -Dspark.deploy.zookeeper.dir=/spark&quot;</div><div>            解释</div><div>                spark.deploy.recoveryMode设置成 ZOOKEEPER</div><div>                spark.deploy.zookeeper.urlZooKeeper URL</div><div>                spark.deploy.zookeeper.dir ZooKeeper 保存恢复状态的目录，缺省为 /spark</div><div>        重启集群</div><div>            在任何一台spark节点上启动start-spark-all.sh</div><div>            手动在集群中其他从节点上再启动master进程：sbin/start-master.sh --&gt;在bigdata02</div><div>        通过浏览器方法    bigdata01:8080 /bigdata02:8080--&gt;Status: STANDBY Status: ALIVE</div><div>            验证HA，只需要手动停掉master上spark进程Master，等一会slave01上的进程Master状态会从STANDBY编程ALIVE</div><div>=====================================================================</div><div>名词解释：</div><div>ClusterManager：在Standalone模式中即为Master（主节点），控制整个集群，监控Worker。在YARN模式中为资源管理器。</div><div>Worker：从节点，负责控制计算节点，启动Executor。在YARN模式中为NodeManager，负责计算节点的控制。</div><div>Driver：运行Application的main()函数并创建SparkContext。</div><div>Executor：执行器，在worker node上执行任务的组件、用于启动线程池运行任务。每个Application拥有独立的一组Executors。</div><div>SparkContext：整个应用的上下文，控制应用的生命周期。</div><div>RDD：Spark的基本计算单元，一组RDD可形成执行的有向无环图RDD Graph。</div><div>DAG Scheduler：实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。</div><div>TaskScheduler：将任务（Task）分发给Executor执行。</div><div>Stage：一个Spark作业一般包含一到多个Stage。</div><div>Task：一个Stage包含一到多个Task，通过多个Task实现并行运行的功能。</div><div>Transformations：转换(Transformations) (如：map, filter, groupBy, join等)，Transformations操作是Lazy的，也就是说从一个RDD转换生成另一个RDD的操作不是马上执行，Spark在遇到Transformations操作时只会记录需要这样的操作，并不会去执行，需要等到有Actions操作的时候才会真正启动计算过程进行计算。</div><div>Actions：操作(Actions) (如：count, collect, save等)，Actions操作会返回结果或把RDD数据写到存储系统中。Actions是触发Spark启动计算的动因。</div><div>SparkEnv：线程级别的上下文，存储运行时的重要组件的引用。</div><div>SparkEnv内创建并包含如下一些重要组件的引用。</div><div>MapOutPutTracker：负责Shuffle元信息的存储。</div><div>BroadcastManager：负责广播变量的控制与元信息的存储。</div><div>BlockManager：负责存储管理、创建和查找块。</div><div>MetricsSystem：监控运行时性能指标信息。</div><div>SparkConf：负责存储配置信息。</div><div>在spark集群中部署spark作业，加载hdfs文件的时候：</div><div>    Caused by: <a href="http://java.net.unknownhostexception/">java.net.UnknownHostException</a>: ns1</div><div>解决之道：</div><div>    将$SPARK_HOME/conf/spark-default.conf.template cp成为$SPARK_HOME/conf/spark-default.conf</div><div>    然后在该文件的最后一行添加一句话：</div><div>        spark.files $HADOOP_HOME/etc/hadoop/hdfs-site.xml,$HADOOP_HOME/etc/hadoop/core-site.xml</div><div>    </div><div>spark-on-yarn</div><div>&lt;property&gt;</div><div>    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;</div><div>    &lt;value&gt;false&lt;/value&gt;</div><div>&lt;/property&gt;</div><div>&lt;property&gt;</div><div>    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</div><div>    &lt;value&gt;false&lt;/value&gt;</div><div>&lt;/property&gt;            </div><div>            </div><div>            </div></span>
</div></body></html> 