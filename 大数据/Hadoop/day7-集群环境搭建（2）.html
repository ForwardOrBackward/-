<html>
<head>
  <title>day7-集群环境搭建（2）</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/603932 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 12pt;
    }
  </style>
</head>
<body>
<a name="1343"/>
<h1>day7-集群环境搭建（2）</h1>
<div>
<table bgcolor="#D4DDE5" border="0">
<tr><td><b>创建时间：</b></td><td><i>2019/8/4 19:06</i></td></tr>
<tr><td><b>更新时间：</b></td><td><i>2021/4/28 14:07</i></td></tr>
</table>
</div>
<br/>

<div>
<span><div><span style="color: rgb(255, 0, 0); font-weight: bold;">1、伪分布式hadoop集群搭建的步骤：</span></div><div><br/></div><div><font style="font-size: 16pt;"><span style="font-size: 16pt; color: rgb(166, 0, 196); font-weight: bold;">首先要确保所有服务器的登录用户是hadoop用户，而不是root用户！！！！！</span></font></div><div><span style="color: rgb(255, 0, 0);">安装步骤：</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">        1）获取软件安装包</span></div><div><span style="color: rgb(255, 0, 0);">        2）规划安装目录，然后加压缩安装包到对应的安装目录</span></div><div><span style="color: rgb(255, 0, 0);">        3</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">修改配置文件 + 配置环境变量</span></div><div><span style="color: rgb(255, 0, 0);">        4</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">初始化，启动，验证</span></div><div><br/></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">详细步骤：</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">（</span><span style="color: rgb(255, 0, 0);">1</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">规划安装目录</span></div><div>            比较通用的安装目录：/opt  /usr 当中  </div><div>            但是为了给新人避免权限问题，直接规划安装目录就是<span style="color: rgb(166, 0, 196);">当前用户的主目录</span>当中的apps目录</div><div><span style="color: rgb(255, 0, 0);">        在secureCRT 的send chat to all sessions窗口给所有服务器在家目录下创建两个新的文件夹：apps和data</span></div><div><span style="color: rgb(255, 0, 0);">            mkdir /home/hadoop/apps</span></div><div><span style="color: rgb(255, 0, 0);">            mkdir /home/hadoop/data</span></div><div><span style="color: rgb(255, 0, 0);">            </span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">（</span><span style="color: rgb(255, 0, 0);">2</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">获取软件安装包（该Hadoop安装包是用centos编译过的） </span><span style="color: rgb(255, 0, 0);">hadoop-2.7.4-with-centos-6.7.tar.gz</span></div><div><span style="color: rgb(255, 0, 0);">            </span><span style="color: rgb(255, 0, 0);">在SecureCRT按 alt+p 键进入SFTP文件传输界面</span></div><div><span style="color: rgb(255, 0, 0);">                </span><span style="color: rgb(26, 173, 224);">sftp&gt;</span> <span style="color: rgb(255, 0, 0);">put</span> <span style="color: rgb(77, 206, 29);">d:/暑假Hadoop/软件/</span><span style="color: rgb(77, 206, 29);">hadoop-2.7.4-with-centos-6.7.tar.gz</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">（</span><span style="color: rgb(255, 0, 0);">3</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">解压缩</span></div><div><span style="color: rgb(255, 0, 0);">            </span>安装目录： /home/hadoop/apps</div><div><span style="color: rgb(255, 0, 0);">            tar -zxvf </span><span style="color: rgb(255, 0, 0);">hadoop-2.7.4-with-centos-6.7.tar.gz</span> <span style="color: rgb(255, 0, 0);">-C /home/hadoop/apps</span></div><div><span style="color: rgb(255, 0, 0);">        </span></div><div><span style="color: rgb(255, 0, 0);">    （4</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">修改配置文件   （修改配置文件的作用可见附录：附录1 </span><span style="font-weight: bold;">Hadoop 的配置文件修改的含义</span><span style="color: rgb(255, 0, 0);">）</span></div><div><br/></div><div><span style="color: rgb(166, 0, 196);">           修改配置文件最好将当前工作目录先cd到配置文件的目录：</span></div><div><span style="color: rgb(166, 0, 196);">                    cd /home/hadoop/apps/hadoop-2.7.4/etc/hadoop</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">            1）vim hadoop-env.sh </span></div><div><span style="color: rgb(255, 0, 0);">                        找到</span><span style="color: rgb(166, 0, 196);">JAVA_HOME</span><span style="color: rgb(255, 0, 0);">变量后，将后面的值改为如下形式</span></div><div><span style="color: rgb(255, 0, 0);">                                export JAVA_HOME=/usr/local/java/</span><span style="color: rgb(77, 206, 29);">jdk1.8.0_73</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">            2）vim core-site.xml</span></div><div><span style="color: rgb(255, 0, 0);">                        找到 &lt;configuration&gt;</span></div><div><span style="color: rgb(255, 0, 0);">                                &lt;/configuration&gt; 配置标签</span></div><div><span style="color: rgb(255, 0, 0);">                        在里面添加如下属性：</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">                        </span><span style="color: rgb(255, 0, 0);">&lt;property&gt;</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">                                        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">&lt;value&gt;</span><a href="hdfs://hadoop02:9000/" style="color: rgb(255, 0, 0);">hdfs://hadoop</a><a href="hdfs://hadoop02:9000/" style="color: rgb(77, 206, 29);">02</a><a href="hdfs://hadoop02:9000/" style="color: rgb(255, 0, 0);">:9000</a><span style="color: rgb(255, 0, 0);">&lt;/value&gt;</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">                        &lt;/property&gt;</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">                        &lt;property&gt;</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">                                        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">                                        &lt;value&gt;/home/hadoop/hadoopdata&lt;/value&gt;</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">                        &lt;/property&gt;</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">   </span> 如图所示：（<span style="color: rgb(166, 0, 196);">接下来的hdfs-site.xml、mapred-site.xml、yarn-site.xml三个文件也是如此法炮制</span>）</div><div><span style="color: rgb(255, 0, 0);"><img src="day7-集群环境搭建（2）_files/Image.png" type="image/png" data-filename="Image.png" width="847"/></span></div><div><span style="color: rgb(255, 0, 0);">                        </span></div><div><span style="color: rgb(255, 0, 0);">            3）vim hdfs-site.xml</span></div><div><span style="color: rgb(255, 0, 0);">                </span><span style="color: rgb(255, 0, 0);">找到 &lt;configuration&gt;</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">&lt;/configuration&gt; 配置标签</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">在里面添加如下属性：</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);">&lt;property&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;value&gt;/home/hadoop/hadoopdata/name&lt;/value&gt;</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);">&lt;/property&gt;</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);">&lt;property&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;value&gt;/home/hadoop/hadoopdata/data&lt;/value&gt;</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);">&lt;/property&gt;</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);">&lt;property&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;name&gt;dfs.replication&lt;/name&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;value&gt;2&lt;/value&gt;</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);">&lt;/property&gt;</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);">&lt;property&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;name&gt;dfs.secondary.http.address&lt;/name&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;value&gt;hadoop</span><span style="color: rgb(77, 206, 29);">03</span><span style="color: rgb(255, 0, 0);">:50090&lt;/value&gt;</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);">&lt;/property&gt;</span></div><div style="margin-left: 120px;"></div><div><span style="color: rgb(255, 0, 0);">            4）cp </span><span style="color: rgb(255, 0, 0);">mapred-site.xml.template </span><span style="color: rgb(255, 0, 0);">mapred-site.xml   </span></div><div><span style="color: rgb(168, 168, 168);">                      #配置文件库里本身没有mapred-site.xml文件，但有它的模板文件mapred-site.xml.template。所</span></div><div><span style="color: rgb(168, 168, 168);">                        #以先cp一份并重命名</span></div><div><span style="color: rgb(255, 0, 0);">                  vim </span><span style="color: rgb(255, 0, 0);">mapred-site.xml</span></div><div><span style="color: rgb(255, 0, 0);">                  </span><span style="color: rgb(255, 0, 0);">找到 &lt;configuration&gt;</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">  </span><span style="color: rgb(255, 0, 0);">&lt;/configuration&gt; 配置标签</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">  在里面添加如下属性：</span></div><div><span style="color: rgb(255, 0, 0);">                        </span><span style="color: rgb(255, 0, 0);">&lt;property&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span></div><div style="margin-left: 200px;"><span style="color: rgb(255, 0, 0);">&lt;value&gt;yarn&lt;/value&gt;</span></div><div style="margin-left: 120px;"><span style="color: rgb(255, 0, 0);"> &lt;/property&gt;</span></div><div style="margin-left: 120px;"></div><div><span style="color: rgb(255, 0, 0);">            5）vim yarn-site.xml</span></div><div><span style="color: rgb(255, 0, 0);">                </span><span style="color: rgb(255, 0, 0);">找到 &lt;configuration&gt;</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">&lt;/configuration&gt; 配置标签</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    在里面添加如下属性：</span></div><div style="margin-left: 160px;"><span style="color: rgb(255, 0, 0);">&lt;property&gt;</span></div><div style="margin-left: 240px;"><span style="color: rgb(255, 0, 0);">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span></div><div style="margin-left: 240px;"><span style="color: rgb(255, 0, 0);">&lt;value&gt;hadoop</span><span style="color: rgb(77, 206, 29);">04</span><span style="color: rgb(255, 0, 0);">&lt;/value&gt;</span></div><div style="margin-left: 160px;"><span style="color: rgb(255, 0, 0);">&lt;/property&gt;</span></div><div style="margin-left: 160px;"><span style="color: rgb(255, 0, 0);">&lt;property&gt;</span></div><div style="margin-left: 240px;"><span style="color: rgb(255, 0, 0);">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span></div><div style="margin-left: 240px;"><span style="color: rgb(255, 0, 0);">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span></div><div style="margin-left: 160px;"><span style="color: rgb(255, 0, 0);">&lt;/property&gt;</span></div><div style="margin-left: 160px;"></div><div><span style="color: rgb(255, 0, 0);">            6）指定从节点 </span></div><div><span style="color: rgb(255, 0, 0);">                vim slaves</span></div><div><span style="color: rgb(255, 0, 0);">                删除localhost字段</span></div><div><span style="color: rgb(255, 0, 0);">                并添加所有的从节点的主机名如下形式：</span></div><div style="margin-left: 160px;"><span style="color: rgb(77, 206, 29);">                hadoop02</span></div><div style="margin-left: 160px;"><span style="color: rgb(77, 206, 29);">                hadoop03</span></div><div style="margin-left: 160px;"><span style="color: rgb(77, 206, 29);">                hadoop04</span></div><div style="margin-left: 160px;"><span style="color: rgb(77, 206, 29);">                hadoop05</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">        </span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">（</span><span style="color: rgb(255, 0, 0);">5</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">配置环境变量</span>(配置环境变量的好处当然是快速使用一些hadoop相关的命令,就跟Windows中配置环境变量一样)</div><div>            当前安装hadoop的用户是hadoop, 所以配置的环境变量是hadoop用户变量，root用户和普通用户（hadoop）配</div><div>            置环境变量的目录分别如下：</div><div style="margin-left: 120px;">             root ： /etc/profile</div><div style="margin-left: 120px;">            普通用户（如hadoop用户） : ~/.bashrc    ~/.bash_profile  两个目录均可</div><div><br/></div><div><span style="color: rgb(255, 0, 0);">            我们选择 .bashrc 文件来配置环境变量。</span></div><div><span style="color: rgb(255, 0, 0);">                  vim /home/hadoop/.bashrc</span></div><div><span style="color: rgb(255, 0, 0);">                        在末尾添加如下两行：</span></div><div style="margin-left: 80px;"><span style="color: rgb(255, 0, 0);">            export HADOOP_HOME=/home/hadoop/apps/hadoop-2.7.4</span></div><div style="margin-left: 80px;"><span style="color: rgb(255, 0, 0);">            export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span></div><div style="margin-left: 80px;"></div><div>            <span style="color: rgb(255, 0, 0);">    配置完成后记得重新加载配置文件:</span></div><div style="margin-left: 40px;"><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">source</span> <span style="color: rgb(255, 0, 0);">/home/hadoop/</span><span style="color: rgb(255, 0, 0);">.bashrc</span></div><div style="margin-left: 40px;"></div><div style="margin-left: 40px;">    hadoop的生态体系各组件的环境变量如下:(需要注意的是hadoop配置了两个命令文件夹的路径,一个bin一个sbin,而</div><div style="margin-left: 40px;">                                                                    生态体系的其他组件的只有一个命令文件夹bin)</div><div>            <img src="day7-集群环境搭建（2）_files/Image [1].png" type="image/png" data-filename="Image.png" width="953"/></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">（</span><span style="color: rgb(255, 0, 0);">6</span><span style="color: rgb(255, 0, 0);">）将当前服务器配置好的hadoop安装目录文件以及配置好的环境变量，</span><span style="color: rgb(166, 0, 196);">在secureCRT 的send chat to all sessions窗口</span><span style="color: rgb(255, 0, 0);">，</span></div><div><span style="color: rgb(255, 0, 0);">        分发给其他所有服务器</span></div><div><span style="color: rgb(255, 0, 0);">         scp -r hadoop@hadoop</span><span style="color: rgb(77, 206, 29);">02</span><span style="color: rgb(255, 0, 0);">:/home/hadoop/apps/</span><span style="color: rgb(77, 206, 29);">hadoop-2.7.4/</span><span style="color: rgb(255, 0, 0);"> /home/hadoop/apps/</span><span style="color: rgb(77, 206, 29);">hadoop-2.7.4/</span></div><div><span style="color: rgb(255, 0, 0);">         </span><span style="color: rgb(255, 0, 0);">scp -r hadoop@hadoop</span><span style="color: rgb(77, 206, 29);">02</span><span style="color: rgb(255, 0, 0);">:/home/hadoop/.bashrc /home/hadoop/.bashrc</span></div><div><span style="color: rgb(255, 0, 0);">         source</span> <span style="color: rgb(255, 0, 0);">/home/hadoop/</span><span style="color: rgb(255, 0, 0);">.bashrc</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">（</span><span style="color: rgb(255, 0, 0);">7</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">初始化</span></div><div style="margin-left: 80px;"><span style="color: rgb(166, 0, 196);">记得，只在“指定为hdfs</span><span style="color: rgb(166, 0, 196); font-weight: bold;">主</span><span style="color: rgb(166, 0, 196);">节点（namenode）的节点”进行初始化</span><span style="color: rgb(255, 0, 0);">（根据上面的配置文件，这里的hdfs主节点是hadoop02，所以，</span><span style="font-size: unset; color: rgb(255, 0, 0); font-family: unset;">只需在hadoop02执行以下命令）</span></div><div><span style="color: rgb(255, 0, 0);">                        hadoop namenode -format</span></div><div><br/></div><div>                初始化成功的标志是如图红行：<img src="day7-集群环境搭建（2）_files/Image [2].png" type="image/png" data-filename="Image.png"/></div><div style="margin-left: 40px;">若初始化不成功，则再次执行命令：<span style="color: rgb(255, 0, 0);">hadoop namenode -format   </span>直到初始化成功。记住，初始化命令执行</div><div style="margin-left: 40px;">成功后不要再去执行，否则hadoop集群又会变成一个全新的集群，里面储存的用户数据全部会被清空</div><div style="margin-left: 40px;"><br/></div><div style="margin-left: 40px;">初始化成功后，hdfs主节点 /home/hadoop/hadoopdata/name/current 目录下会有如下四个配置文件</div><div><span style="color: rgb(255, 0, 0);">            -rw-rw-r-- 1 hadoop hadoop 323 Nov 28 10:33 fsimage_0000000000000000000</span></div><div><span style="color: rgb(255, 0, 0);">            -rw-rw-r-- 1 hadoop hadoop  62 Nov 28 10:33 fsimage_0000000000000000000.md5</span></div><div><span style="color: rgb(255, 0, 0);">            -rw-rw-r-- 1 hadoop hadoop   2 Nov 28 10:33 seen_txid</span></div><div><span style="color: rgb(255, 0, 0);">            -rw-rw-r-- 1 hadoop hadoop 207 Nov 28 10:33 VERSION</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">（</span><span style="color: rgb(255, 0, 0);">8</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">启动集群</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">            启动HDFS集群： start-dfs.sh   </span></div><div style="margin-left: 120px;"><span style="color: rgb(166, 0, 196);">最好在HDFS 上的主节点启动 HDFS</span>，其实在哪里启动并无关系，但为了方便记忆，最好在主节点上启动。</div><div style="margin-left: 120px;">第一次启动时要不断输入yes，一直输入到跳出输入框为止</div><div style="margin-left: 120px;"><br/></div><div style="margin-left: 80px;">启动成功的界面如下图所示。虽然第一次启动后的样子和这个不太一样，但也应该包含这些行，否则可能有些节点没有启动成功。启动成功后，下次再启动时画面应该和这个一模一样</div><div><span style="color: rgb(255, 0, 0);"><img src="day7-集群环境搭建（2）_files/Image [3].png" type="image/png" data-filename="Image.png"/></span></div><div><span style="color: rgb(255, 0, 0);">            启动YARN集群： start-yarn.sh</span></div><div style="margin-left: 120px;"><span style="color: rgb(166, 0, 196);"><span style="color: rgb(166, 0, 196); font-weight: bold;">只能</span>在 YARN 主节点启动 YARN</span>。要求在 YARN 主节点进行启动，否则 ResourceManager 主进</div><div style="margin-left: 120px;">程会启动不成功，需要额外手动启动。第一次启动时要不断输入yes，一直输入到跳出输入框为止</div><div style="margin-left: 120px;"><br/></div><div style="margin-left: 80px;">启动成功的界面如下图所示。虽然第一次启动后的样子和这个不太一样，但也应该包含这些行，否则可能有些节点没有启动成功。启动成功后，下次再启动时画面应该和这个一模一样</div><div><span style="color: rgb(255, 0, 0);"><img src="day7-集群环境搭建（2）_files/Image [4].png" type="image/png" data-filename="Image.png"/></span><span style="color: rgb(255, 0, 0);">            </span></div><div><span style="color: rgb(255, 0, 0);">            如果需要，假设有某个节点没有启动成功，则需要用到启动某个节点的某个进程的命令，启动hdfs节点和yarn节点的</span></div><div><span style="color: rgb(255, 0, 0);">                命令分别如下：（注意：要启动哪个节点的某进程，就要到哪个节点去执行命令）</span></div><div><span style="color: rgb(255, 0, 0);">            hadoop-daemon.sh start namenode/datanode</span></div><div><span style="color: rgb(255, 0, 0);">            yarn-daemon.sh start resourcemanager/nodemanager</span></div><div>    下图是所有节点的相应进程都完美启动时的样子：</div><div><img src="day7-集群环境搭建（2）_files/Image [5].png" type="image/png" data-filename="Image.png"/></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">（</span><span style="color: rgb(255, 0, 0);">9</span><span style="color: rgb(255, 0, 0);">）</span><span style="color: rgb(255, 0, 0);">验证集群是否安装、启动正常</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">            1）检测进程是否正常  ：jps</span></div><div><span style="color: rgb(255, 0, 0);">            2）检测web页面是否正常：</span></div><div style="margin-left: 160px;"><span style="color: rgb(255, 0, 0);">hdfs 集群信息 web 管理界面地址：   </span><a href="http://hadoop02:50070/">http://hadoop02:50070</a></div><div style="margin-left: 160px;"><span style="color: rgb(255, 0, 0);">mapreduce 运行状态信息 web 管理界面：    </span><a href="http://hadoop04:8088/">http://hadoop04:8088</a></div><div><span style="color: rgb(255, 0, 0);">            3）做一个简单的使用</span></div><div><span style="color: rgb(255, 0, 0);">                    a、上传文件到hdfs集群：</span><span style="color: rgb(255, 0, 0);">hadoop fs -put</span> <span style="color: rgb(77, 206, 29);">filepath</span> <span style="color: rgb(77, 206, 29);">destpath </span><span style="color: rgb(255, 0, 0);">（用于测试hdfs集群是否能正常使用）</span></div><div>                        <span style="color: rgb(255, 0, 0);">如将hadoop02中的hadoop的安装包上传到hdfs集群的</span><span style="color: rgb(166, 0, 196);">根</span><span style="color: rgb(255, 0, 0);">目录下:</span></div><div>                        <span style="color: rgb(255, 0, 0);">hadoop fs -put</span> <span style="color: rgb(77, 206, 29);">hadoop-2.7.4-with-centos-6.7.tar.gz</span> <a href="hdfs://hadoop02:9000/" style="color: rgb(77, 206, 29);">hdfs://hadoop02:9000/</a></div><div>                        也可以直接写成：</div><div><span style="color: rgb(255, 0, 0);">                        hadoop fs -put</span> <span style="color: rgb(77, 206, 29);">hadoop-2.7.4-with-centos-6.7.tar.gz</span> <span style="color: rgb(77, 206, 29);">/  </span></div><div>                        说明不带前缀 <a href="hdfs://hadoop02:9000/">hdfs://hadoop02:9000</a> 也是可以的，结果都一样。hdfs的文件系统和linux的文件</div><div>                           系统使用规则是一样的，可以放心使用。</div><div><span style="color: rgb(255, 0, 0);">                    b、运行一个MapReduce的jar包来求圆周率PI（用于测试yarn集群是否</span><span style="color: rgb(255, 0, 0);">能正常使用</span><span style="color: rgb(255, 0, 0);">）</span></div><div><span style="color: rgb(255, 0, 0);">                        cd /home/hadoop/apps/hadoop-2.7.4/share/hadoop/mapreduce</span></div><div><span style="color: rgb(255, 0, 0);">                        hadoop jar hadoop-mapreduce-examples-2.7.4.jar pi 3 3</span></div><div><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">    </span><span style="color: rgb(255, 0, 0);">       </span> 在结尾能得出结果说明正常</div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">2、</span><span style="font-weight: bold;">Hadoop 的配置文件修改的含义</span></div><div>Hadoop 的配置文件位于 hadoop-2.6.5/etc/hadoop/ 文件夹中，需要修改的配置文件的信息的含义如下</div><div>（1）修改 hadoop-env.sh 配置文件，添加 jdk 安装目录配置：</div><div>        找到export JAVA_HOME这一行，将${JAVA_HOME}改成<span style="color: rgb(255, 0, 0);">/usr/local/java/</span><span style="color: rgb(77, 206, 29);">jdk1.8.0_73</span>，也就是把jdk的安装路径</div><div>        放过来，这个路径在 /etc/profile 里已经配过一次，（也就是root用户已经改过了，现在改的是hadoop用户的）</div><div>        可以去那里找到对应的JAVA_HOME变量，找到对应的路径值。</div><div><img src="day7-集群环境搭建（2）_files/Image [6].png" type="image/png" data-filename="Image.png"/></div><div><img src="day7-集群环境搭建（2）_files/Image [7].png" type="image/png" data-filename="Image.png"/></div><div>（2）修改 core-site.xml：</div><div><img src="day7-集群环境搭建（2）_files/Image [8].png" type="image/png" data-filename="Image.png"/></div><div>（3）修改 hdfs-site.xml：</div><div><img src="day7-集群环境搭建（2）_files/Image [9].png" type="image/png" data-filename="Image.png"/></div><div>（4）修改 mapred-site.xml</div><div><img src="day7-集群环境搭建（2）_files/Image [10].png" type="image/png" data-filename="Image.png"/></div><div>（5）修改 yarn-site.xml</div><div><img src="day7-集群环境搭建（2）_files/Image [11].png" type="image/png" data-filename="Image.png"/></div><div>（6）修改slaves</div><div>           这个文件的作用仅仅是用来给start-dfs.sh 和 start-yarn.sh 标识当前集群的从节点的列表，好让这两个</div><div>                    命令在执行的过程当中，能够自动的把对应的所有从节点上的进程都能够启动起来</div><div>            如果配置了slaves文件的内容，那么就可以通过这两个命令直接启动整个集群的所有进程；如果没有配</div><div>                    置，那就表示，所有的进程都必须手动启动</div><div><img src="day7-集群环境搭建（2）_files/Image [12].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">3、重复安装</span></div><div>    </div><div>（1）方法一：再初始化一遍（记得初始化要在hdfs的主节点，也就是运行NameNode的服务器）<span style="color: rgb(166, 0, 196);"> </span></div><div>                     <span style="color: rgb(255, 0, 0);">hadoop namenode -format</span></div><div style="margin-left: 80px;">因为集群搭建成功后，初始化只需要做一次, 也不用关心hadoopdata 是否存在。所</div><div style="margin-left: 80px;">以<span style="color: rgb(166, 0, 196);">如果又做了一次，就相当于重装了一次。</span></div><div>                            </div><div>（2）方法二：如果还想要更加彻底一些的重装，最快的方法是：</div><div>                    rm -rf /home/hadoop/hadoopdata    </div><div>             再初始化一遍：</div><div>                    <span style="color: rgb(255, 0, 0);">hadoop namenode -format</span></div><div>          </div><div>          因为集群的安装目录是： /home/hadoop/apps</div><div style="margin-left: 80px;">            数据目录是： /home/hadoop/hadoopdata</div><div style="margin-left: 80px;">                                  /home/hadoop/hadoopdata/name</div><div style="margin-left: 80px;">                                  /home/hadoop/hadoopdata/data</div><div style="margin-left: 40px;">   而既然集群已经使用过，那么说明安装目录一般是没什么问题的，配置文件也完好。那么只需要删除</div><div style="margin-left: 40px;">    所有的数据目录即可达到快速重装的目的。</div><div style="margin-left: 40px;"><br/></div><div>（3）方法三：删除所有，按照从无到有重来一次。（参照上文<span style="color: rgb(255, 0, 0); font-weight: bold;">1、全分布式hadoop集群搭建的步骤：</span>）</div><div>                    rm -rf /home/hadoop/hadoopdata</div><div>                    rm -rf /home/hadoop/apps/hadoop-2.7.4</div><div><br/></div><div><span style="font-weight: bold;">4、hdfs架构图</span></div><div><span style="font-weight: bold;"><img src="day7-集群环境搭建（2）_files/HDFS架构图.png" type="image/png" data-filename="HDFS架构图.png"/></span></div><div><span style="font-weight: bold;">5、</span><span style="font-weight: bold;">蒙特卡洛算法求圆周率PI的思想</span></div><div><span style="font-weight: bold;"><img src="day7-集群环境搭建（2）_files/蒙特卡洛算法求PI.png" type="image/png" data-filename="蒙特卡洛算法求PI.png"/></span></div><div><br/></div><div><span style="font-weight: bold;">6、启动MapReduce程序的历史任务服务器</span>：(随便在哪个节点启动）</div><div>        mr-jobhistory-daemon.sh start historyserver</div><div>    启动后，以后所有在集群里跑的MapReduce程序的记录全部会被记录下来，不会丢失。否则，过一段时间后MapReduce所跑的程序的记录会随着时间的推移会被系统删除。并且，最好每次将历史任务服务器在同一个节点启动，不然每次在不同的节点启动的话会造成数据的迁移。</div><div><img src="day7-集群环境搭建（2）_files/Image [13].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(134, 0, 164); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">————————————————————手写与上传资料分割线—————————————————</span></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><br/></span></div><div><a href="day7-集群环境搭建（2）_files/hadoop-part2-集群环境搭建.pdf"><img src="day7-集群环境搭建（2）_files/322220ebfab29e1e7b7c82f498e18d81.png" alt="hadoop-part2-集群环境搭建.pdf"></a></div><div><br/></div><div><br/></div><div><br/></div><div>HDFS集群的第一个问题： SPOF</div><div>HDFS 的核心</div><div><br/></div><div>    </div><div>    HDFS的架构 ：  主从架构  ---  一主多从  ---  单点故障问题</div><div><br/></div><div>    HDFS的namenode节点千万不能死。 整个HDFS集群都不能对外提供服务</div><div><br/></div><div>    单点故障：当集群中的一个节点宕机之后，就造成了整个集群不可用。</div><div><br/></div><div>    </div><div>    保证一个HDFS集群始终都能有一个active namenode ：</div><div><br/></div><div>    1、namenode运行的时候，因为会接受所有的客户端的读写数据（上传 和 下载）的请求</div><div><br/></div><div>    任意时刻，无论哪个客户端发送请求，都得保证有namenode去处理</div><div><br/></div><div>    2、假如在正常使用过程当中，如果namenode宕机，最合适的方式，肯定是找一个替代品</div><div><br/></div><div>    active namenode 运行着   正常的运行，能够接收所有客户端的请求进行</div><div><br/></div><div>        共享存储系统（元数据）（生命力非常的顽强）</div><div><br/></div><div>    standby namenode 运行着    但是不接受任何客户端的任何请求，仅仅只是等待active namenode的宕机</div><div><br/></div><div>    namenode是 HDFS 集群的管理节点</div><div>    掌握这整个HDFS集群的关键核心数据（元数据）</div><div><br/></div><div>    </div><div><br/></div><div>    ZooKeeper  </div><div><br/></div><div>    1、确保整个HDFS集群中，始终只有一个namenode (选举算法)</div><div><br/></div><div>        脑裂  brain-split</div><div><br/></div><div>    2、ZooKeeper实现了一个非常优秀的共享系统</div><div><br/></div><div>        用来存储所有的 anmenode的元数据</div><div><br/></div><div>    HDFS集群的HA</div><div><br/></div><div><br/></div><div>    问题：</div><div><br/></div><div>    1、zookeeper是什么架构？ 它能不能是主从架构？</div><div><br/></div><div>    2、Cassandra跟hbase， 数据库  </div><div><br/></div><div>        hbase ：主从架构</div><div>        Cassandra ： 无主架构</div><div><br/></div><div><br/></div><div>    </div><div>HDFS集群的第二个问题：压力问题</div><div><br/></div><div>HDFS ： 主从架构</div><div><br/></div><div>    HDFS的主节点：namenode  ： 接收和处理所有客户端的读写数据请求</div><div><br/></div><div>    如果集群超大。 如果只有 一个namenode的话， 很多明显。这个namenode会很累</div><div><br/></div><div><br/></div><div>    1、请求的量非常大</div><div><br/></div><div>    2、假如一个客户端要上来进行文件下载。</div><div><br/></div><div>        有一个200T的文件存储在HDFS集群中，如果要进行下载，怎么保证该客户端能够迅速的找到对应的这个200T 文件的所有数据块都存储在那些服务器里面?</div><div><br/></div><div>    客户端要寻找的关于这些所有数据块都分布在那些节点的数据都是  元数据</div><div><br/></div><div>    就是发请求 去 请求namenode告诉客户端 所有数据块的位置</div><div><br/></div><div>    数据的存储方案：</div><div><br/></div><div>    1、磁盘  ： 为了安全</div><div>    2、内存  ： 为了效率</div><div><br/></div><div>    在nemnode节点的内部： 所有的元数据</div><div><br/></div><div>    在内存当中存储了一份完整的，  就是为了保证所有的客户端都能迅速的寻找到任何文件的元数据信息</div><div><br/></div><div>    1、nameonde中的每一条元数据其实就是一个数据块的信息， 150KB</div><div><br/></div><div>        16W * 0.15M = 24000 M   24G</div><div><br/></div><div>        128G 的内存： 1PB</div><div>    </div><div>    2、当namenode节点的内存不足以存储下所有的元数据时。那么怎么解决这个问题？</div><div>        </div><div>        1、加内存</div><div><br/></div><div>        2、一个namenode存不下，使用多个namenode去存</div><div><br/></div><div>                </div><div>    active namenode 和  standby namenode的状态一模一样。  元数据是一模一样</div><div>    first anmenode  和 second namenode 的状态都是acitve ，元数据不一样。</div><div><br/></div><div>    联邦机制</div><div>    first namenode 管理 第一个块池中的所有数据块的元数据信息： BP-2344</div><div>    second namenode 管理 第二个块池中的所有数据块的元数据信息： BP-2355</div><div><br/></div><div>    联邦机制(namenode之间是兄弟关系)</div><div><br/></div><div>    1、如果不能交叉，那就意味着，物理界线   就是两个完全独立的集群</div><div><br/></div><div>    2、如果能交叉。 每个datanode都可以为不同的namneode去存储元数据。</div><div>        怎么区分这些数据块到底是属于那个namenode ?</div><div><br/></div><div>        靠 块池</div><div>    </div><div>    </div><div>    在联邦集群中，每个namenode也得做高可用配置</div><div><br/></div><div><br/></div><div>hadoop的集群架构：</div><div><br/></div><div>1、单机模式</div><div>2、分布式</div><div>    主从架构</div><div>    HA集群</div><div>    联邦集群</div><div><br/></div><div><br/></div><div>设计 存储系统  的时候 一定要兼顾  计算</div><div>设计 计算模型  的时候 一定要兼顾  存储</div><div><br/></div><div>逻辑概念</div><div>物理概念</div><div><br/></div><div>逻辑切分</div><div>物理切分</div><div><br/></div><div>抽象--逻辑   HDFS 分布式文件系统 抽象的文件 逻辑系统</div><div><br/></div><div>架构在多个不同的linux文件系统之上</div><div><br/></div><div>而仅仅是包含我们配置的那个目录： /home/hadoop/hadoopdata/data</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div>数据块  +  副本</div><div><br/></div><div>如果A和B 都不足128M ， 并且就算加起来也不足128M ， 他们也不会被存为一个数据块</div><div><br/></div><div><br/></div><div>一个数据块一定是属于某个一个特定文件的</div><div>一个文件被切分的时候，只有当他超过规定的切块大小的时候才会被切分。</div><div>如果一个文件就是小于规定的数据块的大小，那么就存为一个单独的数据块</div><div>如果一个文件file1是100M , 那么现在你告诉我：这个数据块blk-01到底是占用128M的空间，还是100M的空间？  100M</div><div><br/></div><div><br/></div><div>HDFS的设计者：</div><div>    HDFS的存储机制里面；  归档  +  压缩</div><div>mongodb ：文档数据库</div><div>mysql : 关系型数据库</div><div>redis ： 数据结构数据库</div><div>memcached ： key-value数据库</div><div>hbase ： 列式存储的NoSQL数据库</div><div>neo4j : 图数据库</div><div><br/></div><div>最短寻路算法</div><div><br/></div><div><br/></div><div>大量的小文件：  mongodb</div><div>音乐网站： .mp3</div><div>图片服务器  ：  图片的查询 和 存储</div><div><br/></div><div><br/></div><div>QPS : query per second</div><div><br/></div><div><br/></div><div>EB---PB -- TB --GB ---MB  ---KB</div><div><br/></div></span>
</div></body></html> 