<html>
<head>
  <title>大数据与Hadoop系列之压缩(一)</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/603932 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 12pt;
    }
  </style>
</head>
<body>
<a name="6628"/>
<h1>大数据与Hadoop系列之压缩(一)</h1>
<div>
<table bgcolor="#D4DDE5" border="0">
<tr><td><b>创建时间：</b></td><td><i>2021/1/15 13:54</i></td></tr>
<tr><td><b>更新时间：</b></td><td><i>2021/4/12 19:09</i></td></tr>
</table>
</div>
<br/>

<div>
<span><div><span style="font-weight: 700;">Hadoop压缩简介</span></div><div><div><a href="https://www.cnblogs.com/wuyudong/p/4378357.html">https://www.cnblogs.com/wuyudong/p/4378357.html</a></div><div><span style="font-weight: 400;">Hadoop作为一个较通用的海量数椐处理平台，在使用压缩方式方面，主要考虑压缩速度和压缩文件的可分割性。</span></div><div><span style="font-weight: 400;">所有的压缩算法都会考虑时间和空间的权衡，更快的压缩和解压缩速度通常会耗费更多的交间（压缩比较低）例如：通过gzip命令压缩数据时，用户可以设置不同的选项来选择速度优先或空间优先。选项-1表示优先考虑速度，选项-9表示空间最优，可以获得最大的压缩比。</span></div><div><span style="font-weight: normal;">需要注意的是：有些压缩算法的压缩和解压缩速度会有比较大的差别：gzip和zip是通用的压缩工具，在时间/空间处理上相对平衡，gzip2压缩比gzip和zip更有效，但速度较慢，而且bzip2的解压缩速度快于它的压缩速度。</span></div><div><span style="font-weight: 400;">当使用MapReduce处理压缩文件时, 需要考虑压缩文件的可分割性。例如我们需要对保存在HDFS上的一个大小为1GB的文本文件进行处理，当HDFS的数据块大小为64MB的情况下，该文件被存储为16块，对应的MapReduce作业将会将该文件分为16个输入分片，提供给16个独立的Map任务进行处理。但如果该文件是一个gzip格式的压缩文件（大小也为1GB）。这时，MapReduce作业不能够将该文件分为16个分片，因为不可能从gzip数椐流中的某个点开始，进行数据解压，但是，如果该文件是一个bzip2格式的压缩文件，那么</span><span style="font-size: unset; color: unset; font-family: unset;">MapReduce作业可以通过bzip2格式压缩文件中的块，将输入数据划分为若干输入分片，并从块开始处开始解压缩数据。bzip2格式压缩文件中，块与块间提供了一个48位的同步标记，因此，bzip2支持数据分割。</span></div><div><span style="font-weight: 400;">下图列出了一些可以用于Hadoop的常见压缩格式以及特性。</span></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/1528680417683211969b129" type="image/jpeg" data-filename="1528680417683211969b129" height="160" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="789"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><span style="font-weight: 400;">为了支抟多种压缩解压缩算法，Hadoop引入了编码/解码器。</span></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/1528680436085f5d49faa79" type="image/jpeg" data-filename="1528680436085f5d49faa79" height="155" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="879"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><h1><span style="font-weight: 700;">Hadoop压缩框架</span></h1><div><span style="font-weight: 400;">Hadoop通过编码/解码器为基础的抽象工厂法，提供了一个可扩展的框架，支持多种压缩方法，下面就来研究Hadoop压缩框架的实现。</span></div><div><img src="大数据与Hadoop系列之压缩(一)_files/compress类图.png" type="image/png" data-filename="compress类图.png"/></div><div><span style="font-weight: 700;">1.编码/解编码</span></div><div><span style="font-weight: 400;">CompressionCodec接口实现编码/解编码，使用的是抽象工厂的设计模式。CompressionCodec提供一系列的方法，用于创建特定压缩算法的相关设施。</span></div><div><span style="font-weight: 400;">CompressionCodec中方法很对称，一个压缩功能总能对应着一个解压缩编码功能。其中，与压缩相关的方法包括:</span></div><div style="margin-left: 40px;"><span style="font-weight: 700;">createOutputStream</span></div><div style="margin-left: 40px;"><span style="font-weight: 400;">    使用压缩器Compressor，在底层输出流out的基础上创建对应的压缩流</span></div><div style="margin-left: 40px;"><span style="font-weight: 700;">createCompressor</span></div><div style="margin-left: 40px;"><span style="font-weight: 400;">    创建压缩算法对应的压缩器</span></div><div><span style="font-weight: 400;">CompressionCodec中还提供了获取对应文件扩展名的方法getDefaultExtension，如对org.apache.hadoop.io.cpmpress.BZip2Codec，改方法返回字符串&quot;.bz2&quot;，注意字符串的第一个字符，相关代码如下。</span></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286818905731e09829209" type="image/jpeg" data-filename="15286818905731e09829209" height="317" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/1528681906603a62970a90b" type="image/jpeg" data-filename="1528681906603a62970a90b" height="316" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/1528681922598649c1cb0d2" type="image/jpeg" data-filename="1528681922598649c1cb0d2" height="235" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/152868194294355d4e10bdc" type="image/jpeg" data-filename="152868194294355d4e10bdc" height="310" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/1528681957989cac639674c" type="image/jpeg" data-filename="1528681957989cac639674c" height="175" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="650"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><span style="font-weight: 400;">CompressionCodecFactory适Hadoop压缩框架中的另一个类，它应用了工厂方法，使用者可以通过它提供的方法获得CompressionCodec。</span></div><h1><span style="font-weight: 700;">注意</span></h1><div><span style="font-weight: 700;">抽象工厂方法和工厂方法这两个设计模式有很大的区别，抽象工厂方法用于创建一系列相关或互相依赖的对象，如CompressionCodec可以获得和某一个压縮算法相关的对象，包括压缩流和压缩流等?而工厂方法（严格来说，CompressionCodecFactory是参数化工厂方法），用于创建多种产品，如通过CompressionCodecFactory的getCodec()方法，可以刻建GzipCodec对象或BZip2Codec对象。</span></div><div><span style="font-weight: 400;">在前面的实例中已经使用过getCodec()方法，为某一个压缩文件寻找对应的CompressionCodec。为了分析该方法，需要了解CompressionCodec类中保存文件扩展名和CompressionCodec映射关系的成员变董codecs。</span></div><div><span style="font-weight: 400;">codecs是一个有序映射表，即它本身是一个Map，同时它对Map的键排序，下面是codecs中保存的一个可能的映射关系：</span></div><div><span style="font-weight: 400;">{</span></div><div><span style="font-weight: 400;">2zb.：org.apache.hadoop.io.congress.BZip2Codec,</span></div><div><span style="font-weight: 400;">etalfed.：org.apache.hadoop.io.congress.DeflateCodec,</span></div><div><span style="font-weight: 400;">yppans.:org.apache.hadoop.io.compress.SnappyCodec,</span></div><div><span style="font-weight: 400;">zg.：org.apache.hadoop.io.compress.GzipCodec</span></div><div><span style="font-weight: 400;">}</span></div><div><span style="font-weight: 400;">可以看到，Map中的键是排序的，getCodec()方法的输入是Path对象，保存者文件路径，如实例中的“README.txt.bz2”.</span></div><div><span style="font-weight: 400;">首先通过获取Path对象对应的文件名并逆转该字符串得到“2zb.txt.EMDAER”，然后通过有序映射SortedMap的headMap()方法，查找最接近上述逆转字符串的有序映射的部分视图，如输人“2zb.txt.EMDAER”的查找结采subMap,只包含“2zb.”对应的那个键-值对，</span></div><div><span style="font-weight: 400;">如果输入垃“zg.txt.EMDAER”，則subMap会包含成员变量codccs中保存的所有键-值对，</span></div><div><span style="font-weight: 400;">然后，简单地获取subMap最后一个元素的键，如果该键是逆转文件名的前缀，那么就找到了文件对应的编码/解码器，否則返回空，实现代码如下：</span></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286827315113d5a0153cf" type="image/jpeg" data-filename="15286827315113d5a0153cf" height="408" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286827841113bc07984b0" type="image/jpeg" data-filename="15286827841113bc07984b0" height="453" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><span style="font-weight: 700;">压缩器和解压器</span></div><div><span style="font-weight: 400;">压缩器（Compressor)和解压器（Decompressor)是Hadoop压缩框架中的一对重要概念。</span></div><div><span style="font-weight: 400;">Compressor可以插入压缩输出流的实现中，提供具体的压缩功能：相反，Decompressor提供具体的解压功能并插人CompressionlnputStream中。Compressor和Decompressor的这种设汁，最初是在Java的zlib压缩程序库中引人的，对应的实现分别是java.util.zip.Deflater和java.util.zip.Inflater。下面以Compressor为例介绍这对组件。</span></div><div><span style="font-weight: 400;">Compressor的用法相对复杂，请参考org.hadoopinternal.compress.CompressDemo的compressor()方法，Compressor通过sctlnput()方法接收数椐到内部缓冲区，自然可以多次调用setlnput()方法，但内部缓冲区总是会被写满，如何判断压缩器内部缓冲区是否已满呢？课以通过needsInput()的返回值，如果垃false，表明缓冲区已经满，这时必须通过compress()方法获取压缩后的数据，释放缓冲区空间.</span></div><div><span style="font-weight: 400;">为了提高压缩效串，并不是每次用户调用sctlnput()方法，压缩器就会立即工作，所以，为了通知压缩器所有数据已经写人，必须使用finish()方法，finish()调用结束后，压缩器缓冲区中保持的已经压缩的数据，可以继续通过compress()方法获得，至于要判断压缩器中是否还有未读取的以缩数据，則擗要利用finished()方法来判断。</span></div><div><span style="font-weight: 700;">注意</span></div><div><span style="font-weight: 700;">finished()和finish()的作用不同，finish()结東数据输入的过程，而finished()返回false,表明压縮器中还有表读取的压堆数据，可以继续通过compress()方法读取。</span></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/152868365256653c1a6dddd" type="image/jpeg" data-filename="152868365256653c1a6dddd" height="295" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="623"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286836647349dcdc2a0d2" type="image/jpeg" data-filename="15286836647349dcdc2a0d2" height="439" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="623"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286836814138ba5882f28" type="image/jpeg" data-filename="15286836814138ba5882f28" height="274" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="570"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><span style="font-weight: 400;">举个栗子：</span></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/1528685019499e9ed985bdc" type="image/jpeg" data-filename="1528685019499e9ed985bdc" height="192" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="292"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286850356739a7bac6585" type="image/jpeg" data-filename="15286850356739a7bac6585" height="302" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286850615700ca7d61485" type="image/jpeg" data-filename="15286850615700ca7d61485" height="349" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286850878867c123bb874" type="image/jpeg" data-filename="15286850878867c123bb874" height="339" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="640"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/152868510032490113563a2" type="image/jpeg" data-filename="152868510032490113563a2" height="224" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="753"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><div><span style="font-weight: normal;"><img src="大数据与Hadoop系列之压缩(一)_files/15286851200332e4cf12841" type="image/jpeg" data-filename="15286851200332e4cf12841" height="68" style="border:0px;outline:0px;overflow-wrap:break-word;max-width:100%;height:auto;box-sizing:border-box;cursor:zoom-in;border-style:none;margin:10px auto;" width="352"/></span></div><p style="outline:0px;padding:0px;overflow-wrap:break-word;overflow:auto hidden;margin:0px 0px 16px;font-weight:400;box-sizing:border-box;font-size:12px;color:rgb(119,119,119);line-height:16px;margin-bottom:0px;text-align:center;"></p></div><div><span style="font-weight: 400;">未完待续........</span></div></div><div><br/></div></span>
</div></body></html> 