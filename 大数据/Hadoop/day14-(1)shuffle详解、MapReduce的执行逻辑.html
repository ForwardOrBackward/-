<html>
<head>
  <title>day14-(1)shuffle详解、MapReduce的执行逻辑</title>
  <basefont face="微软雅黑" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/603932 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: 微软雅黑;
      font-size: 12pt;
    }
  </style>
</head>
<body>
<a name="2562"/>
<h1>day14-(1)shuffle详解、MapReduce的执行逻辑</h1>
<div>
<table bgcolor="#D4DDE5" border="0">
<tr><td><b>创建时间：</b></td><td><i>2019/11/2 16:54</i></td></tr>
<tr><td><b>更新时间：</b></td><td><i>2021/8/7 22:19</i></td></tr>
</table>
</div>
<br/>

<div>
<span><div><span style="font-weight: bold;">一、shuffle概述</span></div><div><span style="font-weight: bold;">(1)为什么要用shuffle</span></div><div><span style="font-weight: bold;"><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/分布式计算编程框架MapReduce的shuffle必要性.png" type="image/png" data-filename="分布式计算编程框架MapReduce的shuffle必要性.png"/></span></div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/环形缓冲区.png" type="image/png" data-filename="环形缓冲区.png"/></div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/Image.png" type="image/png" data-filename="Image.png"/></div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/Image [1].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">二、MapReduce的执行逻辑</span></div><div>(1)<span style="color: rgb(255, 0, 0);">首先执行mapper组件,每个mapTask将数据按行切分好,并按照map方法的规则定义好输出的key和value</span></div><div><span style="color: rgb(255, 0, 0);">map输出的key和value进入环形缓冲区。并且在缓冲区的内存装满了80%之后,就会进行溢写操作,溢出到磁盘</span></div><div><span style="color: rgb(255, 0, 0);">在溢出的过程中:</span></div><div>(2)<span style="color: rgb(255, 0, 0);">执行Partitioner组件,进行分区。</span></div><div>    如果是默认的Partitioner组件<span style="color: rgb(255, 0, 0);">,每个mapTask里的数据分别按照Partitioner组件默认的hashPartition规则进行分区,将一个</span></div><div><span style="color: rgb(255, 0, 0);">        mapTask分成若干个区。job.setNumReduceTasks();设置了有多少个分区,到时候就会有</span></div><div><span style="color: rgb(255, 0, 0);">        多少个分区,也就是说最后会有多少个ReduceTask,也就是会有多少个结果文件</span></div><div>   如果是自定义Partitioner组件,自定义的分区规则也是按照key中的某个字段进行分区,和分组、排序</div><div>        的原理差不多,不过Partitioner组件的分区规则与后面的分组、排序的规则并没有直接的关系</div><div>        比如说我们可以按照key中的a字段进行分区、b字段进行分组、b和c字段进行排序</div><div>(3)<span style="color: rgb(255, 0, 0);">执行sorter组件进行快速排序。</span></div><div>   <span style="color: rgb(255, 0, 0);"> 每个mapTask会在Partitioner阶段结束时将结果数据进行快速排序</span>(sort)(快速排序是所有数据在内存中进行排序),</div><div>    实际上<span style="color: rgb(255, 0, 0);">因为结果数据都是从环形缓冲区里一次次溢出的,所以每次排序只能对一次溢出的结果进行快速排序</span></div><div>(4)<span style="color: rgb(255, 0, 0);">如果有combiner组件, 则会对一个mapTask分成的若干区分别进行聚合操作,并分别对每个mapTask执行一样的操作,</span></div><div><span style="color: rgb(255, 0, 0);">    也就是说combiner的作用域是单个单个的mapTask的数据,每次执行combiner是在一个mapTask</span></div><div><span style="color: rgb(255, 0, 0);">    上执行的,所以是局部聚合,</span><span style="color: rgb(255, 70, 53);">而reducer是对所有maptask汇总过来的数据进行聚合</span></div><div>(5)<span style="color: rgb(255, 0, 0);">将一次溢出(已经分好区,排好序,局部聚合完毕)的结果数据,序列化,写入磁盘</span></div><div>(6)<span style="color: rgb(255, 0, 0);">将一个maptask所有溢出的同一个分区的结果文件进行归并排序</span>。</div><div>    (归并排序的优点是可以将大部分数据放在磁盘中,每次只将小部分数据调入内存进行排序,但归并排序要求所有的子文件</div><div>    是有序的,这样就可以直接进行归并,归并排序是一个不断合并小文件的过程)</div><div>    <span style="color: rgb(255, 0, 0);">此次归并排序会把由同一个mapTask溢出的属于同一个分区的一个个结果数据的小文件合并成一个大文件。</span></div><div>        (当然是同一个分区的数据才进行归并,不同分区的数据是不能归并在一起的)</div><div>(6)<span style="color: rgb(255, 0, 0);">网络传输</span></div><div>(7)<span style="color: rgb(255, 0, 0);">执行sorter组件对一个reduceTask得到的来自所有mapTask的属于该reduceTask的小文件进行归并排序。</span></div><div>    <span style="color: rgb(255, 0, 0);">每个ReduceTask会在reduce阶段开始前进行归并排序(merge)。</span></div><div><span style="color: rgb(255, 0, 0);">    归并排序会把由不同的mapTask传输过来的小文件合并成一个大文件,使得等待该ReduceTask处理的所有数据有序</span></div><div>(8)<span style="color: rgb(255, 0, 0);">执行reducer组件,对每一个key的values集合分别进行一次性集中处理,处理完成后最终一个reduceTask得到一个结果文件</span>。</div><div>    可以看出,在执行reducer前,所有mapTask的数据已经全部汇总到各个分区里,然后每个</div><div>    分区启动一个ReduceTask,对数据进行聚合操作</div><div><br/></div><div><br/></div><div><span style="color: rgb(166, 0, 196);">   所以默认的执行顺序应该是: mapper、分区(Partitioner)、分组和快速排序(sorter)、combiner(可有可无)、</span></div><div><span style="color: rgb(166, 0, 196);">    将溢出数据序列化到磁盘、归并排序、网络传输、反序列化、分组和归并排序(sorter)、reducer。</span></div><div><span style="color: rgb(166, 0, 196);">    </span><span style="color: rgb(166, 0, 196);">   </span> 反序列化也可能是在分组和归并排序之后、reducer之前</div><div><br/></div><div style="box-sizing: border-box; outline: 0px; margin: 0px 0px 16px; padding: 0px; font-size: 16px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; outline: 0px; font-size: 16px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 16px; color: rgb(166, 0, 196); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold; line-height: 26px;">(二)到底在哪里使用combiner?</span></span></div><div style="box-sizing: border-box; outline: 0px; margin: 0px 0px 16px; padding: 0px; font-size: 16px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; outline: 0px; font-size: 16px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 16px; color: rgb(166, 0, 196); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold; line-height: 26px;">1，map输出数据根据分区排序完成后，在写入文件之前会执行一次combiner操作(前提是作业中设置了combiner组件);</span></span></div><div style="box-sizing: border-box; outline: 0px; margin: 0px 0px 16px; padding: 0px; font-size: 16px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; outline: 0px; font-size: 16px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><span style="font-size: 16px; color: rgb(166, 0, 196); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold; line-height: 26px;">2，如果map输出比较大，溢出文件个数大于3(此值可以通过属性</span><a href="http://min.num.spills.for.combine/" style="font-size: 16px; color: rgb(166, 0, 196); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold; line-height: 26px;">min.num.spills.for.combine</a><span style="font-size: 16px; color: rgb(166, 0, 196); font-family: -apple-system, &quot;SF UI Text&quot;, Arial, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif, SimHei, SimSun; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold; line-height: 26px;">配置)时，在merge的过程(多个spill文件合并为一个大文件)中前还会执行combiner操作;</span></span></div><div style="box-sizing: border-box; outline: 0px; margin: 0px 0px 16px; padding: 0px; font-size: 16px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255);"><span style="box-sizing: border-box; outline: 0px; font-size: 16px; overflow-wrap: break-word; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><br/></span></div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/Image [2].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="color: rgb(255, 0, 0); font-weight: bold;">三、MapReduce执行流程要点</span></div><div><br/></div><div>1、<span style="color: rgb(255, 0, 0);">每个mapTask会在map阶段结束时(实际上是在Partitioner之后)将结果数据进行快速排序(sort)(快速排序</span></div><div><span style="color: rgb(255, 0, 0);">    是所有数据在内存中进行排序),使得传输到每个ReduceTask的小文件是有序的;</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">   每个ReduceTask会在reduce阶段开始前进行归并排序(merge)(归并排序的优点是可以将大部分数据放在</span></div><div><span style="color: rgb(255, 0, 0);">    磁盘中,每次只将小部分数据调入内存进行排序,但归并排序要求所有的子文件是有序的,这样就可以</span></div><div><span style="color: rgb(255, 0, 0);">    直接进行归并,归并排序是一个不断合并小文件的过程),归并排序会把由不同的mapTask传输</span></div><div><span style="color: rgb(255, 0, 0);">    过来的小文件合并成一个大文件,使得待该ReduceTask处理的所有数据有序。</span></div><div><br/></div><div>   所以<span style="color: rgb(255, 0, 0);">默认的执行顺序应该是mapper、分区(Partitioner)、分组和快速排序(sorter)、combiner(可有可无)、</span></div><div><span style="color: rgb(255, 0, 0);">    序列化到磁盘、网络传输、反序列化、分组和归并排序(sorter)、reducer。</span></div><div>    从上面的顺序可以看出:</div><div>    (1)分区与后面的分组排序没有任何关系,肯定是先将一个mapTask的结果数据分成若干个区,</div><div>        再对每个分区的数据进行分组排序。因为不按照分区的排序是没有意义的,将来又不会由</div><div>        一个ReduceTask处理,又不会在同一个结果文件,所以不可能是对整个mapTask的结果数据</div><div>        直接进行分组排序,要先分区的</div><div>    (2)<span style="color: rgb(255, 0, 0);">就算有combiner也不会增加sorter组件的使用次数。因为sorter组件本来就会执行两次,只不过两次</span></div><div><span style="color: rgb(255, 0, 0);">        执行的是sorter组件的不同部分,前一次是快速排序,后一次是归并排序。而combiner组件</span></div><div><span style="color: rgb(255, 0, 0);">        本来就是对一个mapTask进行局部聚合汇总,所以也并不需要归并排序来合并多个mapTask</span></div><div><span style="color: rgb(255, 0, 0);">        传输过来的小文件,所以combiner的引入并不会增加任何sorter组件的使用次数,对MapReduce</span></div><div><span style="color: rgb(255, 0, 0);">        的其他组件处理数据的方式也没有任何影响</span></div><div><br/></div><div>    </div><div>2、reduce读到的文件时从磁盘中读的,也就是说序列化要先写到磁盘,然后再从磁盘进行网络传输,然后</div><div>    网络传输也是直接传到磁盘,再从磁盘调入内存,供reducer使用</div><div><br/></div><div>3、reduce阶段之前每个reduceTask的所有数据排好序,则每次reduceTask扫描mapper阶段过来的结果文件</div><div>    只需要扫描一次(每扫描一次就是一组key&quot;相同&quot;的key values集合)</div><div><br/></div><div>4、快速排序是发生在分区之后,也就是数据还没序列化写入磁盘之前,也是进行网络传输之前</div><div><br/></div><div>5、每个mapTask执行完之后,他的结果文件就存储在执行这个mapTask的节点的磁盘当中</div><div><br/></div><div>6、执行mapTask时&quot;数据优先大于算法优先&quot;,也就是说一般待处理的文件的某个数据块备份储存在哪几个节点,</div><div>    那这个数据块将对应启动的mapTask程序,就会在这几个节点中选择一个执行</div><div><br/></div><div>7、一个mapTask中的结果数据不管最后会被分别传输到几个reduceTask中去,<font color="#FF0000">一个mapTask的的结果数据都会将所有分区</font></div><div><font color="#FF0000">    的结果数据储存在同一个文件中</font>,只不过在这个结果文件中已经将结果数据分组排序好了,并且会标识好从第几行</div><div>    到第几行(起始偏移量到结束偏移量)是属于哪个ReduceTask的数据,到时候哪个ReduceTask要数据的时</div><div>    候就可以按照标记传输</div><div>    每个ReduceTask自己需要的数据,会从每个mapTask中获取属于自己分区的数据,传输到ReduceTask自己所在节点</div><div>        的磁盘中形成一个小文件,然后和其他mapTask的传过来形成的文件利用归并排序算法归并成一个大文件</div><div>   也就是说,一个mapTask只会生成一个结果文件,而这个结果文件里的数据会按照分区存储</div><div><br/></div><div>8、<span style="color: rgb(255, 0, 0);">每一个mapTask都会对应一个环形缓冲区(默认是内存中100M大小的空间),向环形缓冲区写入的数据是map方法</span></div><div><span style="color: rgb(255, 0, 0);">    输出的key-value。</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">   其实在写入缓冲区之前,每个key-value的分区编号就已经求出来了,组成了一个三元组&lt;key,value,partition&gt;</span></div><div><span style="color: rgb(255, 0, 0);">    所以,在往缓冲区里写某个key-value时其实是在写一个三元组&lt;key,value,partition&gt;。待缓冲区里数据</span></div><div><span style="color: rgb(255, 0, 0);">    写到80%时,开始把这80%的数据全部溢出。</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">   在溢出的过程中进行先分区(Partitioner)、再分组排序(sorter)、最后局部聚合(combiner)。(这已经是在shuffle阶段了)</span></div><div><span style="color: rgb(255, 0, 0);">   所谓的&quot;</span><span style="color: rgb(166, 0, 196);">在溢出的过程中</span><span style="color: rgb(255, 0, 0);">&quot;,</span><span style="color: rgb(166, 0, 196);">可能是</span><span style="color: rgb(255, 0, 0);">先把要溢出的所有数据挪到内存的其他地方,然后开始进行分区(Partitioner)、再</span></div><div><span style="color: rgb(255, 0, 0);">    分组排序(sorter)、最后局部聚合(combiner);     </span><span style="color: rgb(166, 0, 196);">也可能是</span><span style="color: rgb(255, 0, 0);">直接在环形缓冲区里进行分区(Partitioner)、再分组</span><span style="color: rgb(255, 0, 0);">排序(sorter)、</span></div><div><span style="color: rgb(255, 0, 0);">    最后局部聚合(combiner)。</span></div><div><br/></div><div><span style="color: rgb(255, 0, 0);">    反正分区和排序和局部聚合是要在内存中进行的</span></div><div><br/></div><div>   <span style="color: rgb(166, 0, 196);">进行完分区和排序和局部聚合这些操作后,才是序列化,写入到磁盘</span></div><div><br/></div><div>   分区和排序的方法可能是:用快速排序的方法先把分区号相同的放到一堆,再把每个分区按照key&quot;相同&quot;的进行分组,再在组内</div><div>    用快速排序对key进行排序。</div><div>    </div><div>  <span style="color: rgb(255, 0, 0);"> 在所有数据溢出到磁盘文件后,也会对该mapTask的所有溢出来的小文件进行归并排序(merge),将这些小结果文件</span></div><div><span style="color: rgb(255, 0, 0);">    合并成一个大的结果文件(所以归并排序也并不是只在网络传输后、reducer执行前发生一次)</span></div><div><br/></div><div>9、<span style="color: rgb(255, 0, 0);">真正的shuffle阶段是从map阶段的context.write()写出去之后,到reducer组件的reduce方法接收到key values</span></div><div><span style="color: rgb(255, 0, 0);">    之前</span></div><div><br/></div><div>10、<span style="color: rgb(255, 0, 0);">网络传输之后的归并排序,如果发现要合并的总数据大小(所有小文件的总大小)比较小的话,就直接在内存进行归</span></div><div><span style="color: rgb(255, 0, 0);">    并;如果太大的话,就会放到磁盘,只将即将进行排序的数据放到内存进行排序。</span></div><div><br/></div><div>11、<span style="color: rgb(255, 0, 0);">其实并不是说当所有mapTask都执行成功后,才开始执行reduceTask,而是,当绝大部分的mapTask都执行成功,</span></div><div><span style="color: rgb(255, 0, 0);">    reduceTask就可以提前启动了。提前启动reduceTask的作用是:预先拉取已经执行完毕的mapTask节点上</span></div><div><span style="color: rgb(255, 0, 0);">    中间结果,先对部分结果做合并。</span></div><div><br/></div><div>12、序列化:</div><div>(1)定义： </div><div>i. <span style="font-size: unset; color: unset; font-family: unset;">序列化：把对象状态按照一定的格式转换成有序字节流，以便在网络上传输或者保存在本地文件中 </span></div><div><span style="font-size: unset; color: unset; font-family: unset;">ii. 反序列化：从文件中或网络上获得序列化后的对象字节流后，根据字节流中所保存的对象状态及描述信息，重建对象</span></div><div>(2). 序列化的作用</div><div>  将对象变成一串字节流</div><div><br/></div><div>  不用序列化能否保存磁盘上？</div><div>  可以，但是你要将对象中一个个的基本属性进行写入操作，比如int之流, 当然,   按你自己希望的顺序，.</div><div>  </div><div>  序列化和持久化之间的关系</div><div>  序列化过程是持久化的一种方式，当然Java中你可以选择适当的方式编码(utf-8)。</div><div>  </div><div>  Java序列化的过程就是将对象按照Java约定的序列化方式变成一串字节流，当然大家都知道那是很烂的。。。。</div><div>  </div><div> (3)序列化和压缩的目的都是为了节省空间？有啥区别？</div><div>  这里可以打个比方:</div><div>  序列化可理解为将一个组合办公桌（对象）按标准拆解为散件，以方便运输（网络上传输），到达目的地后再重新组装成一个整体办公桌，所以序列化的目的不是压缩，而是变成  流以方便网络传输并能重新组装为对象,  后来大家又发现一张桌子有四条腿，不需要运输1111这种方式，改成1,4就可以了，这就是压缩了。</div><div><br/></div><div>  因此， 序列化可以理解为对象级别的压缩方式。</div><div><br/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">四、关于各个组件的思考:</span></div><div><br/></div><div>(1)关于sorter</div><div><br/></div><div>sorter的功能是分组和排序。</div><div>默认情况下,分组规则和排序规则是一样的:也就是说,如果不改变分组规则,</div><div>    那么按照key中的a和b进行排序,那么就默认为只有当key中的a和b同时一样时,才认为是同一组的数据。</div><div>   <span style="color: rgb(166, 0, 196);"> 分组的意义</span>在于:<span style="color: rgb(166, 0, 196);">同一组的数据就认为是同一个key</span>(尽管他们可能只有key中的某个字段是相同的),</div><div>    到了reducer阶段就会被调用一次reduce方法就处理完一组,因为reduce方法传入的参数是同一个</div><div>    key的values集合,而不是一对一对的key-value键值对。也就是说<span style="color: rgb(166, 0, 196);">调用一次reduce方法就处理完一个分组</span></div><div>    <span style="color: rgb(166, 0, 196);">的数据</span>。(虽然说同一组的数据会被认为是同一个key,但reducer还是会把所有的key记录下来,</div><div>    因为这些key实际上可能并不相同)</div><div><br/></div><div>    排序是指按照key排序,默认的排序规则是按照key的hash值从小到大排序?</div><div>    而且sorter应该是先分组后排序(分成组后组内再排序)否则先排序后分组不现实)</div><div><br/></div><div>分组应该是按照key中的某个字段相同的进行分组,再按照key中该字段再加上其他字段一起进行排序</div><div>(</div><div>用来分组的key的字段可以和用来排序的key的字段不一样。</div><div>比如说key共有三个字段:name、course、score。</div><div>分组时使用的key的字段是course,即分组时只要course字段相同即认为key相同,即为同一个key。</div><div>排序时使用的key的字段是course和score,即同时按照course和score进行排序。</div><div>但其实Reducer组件只按分组的结果区分是否是相同的key,与排序阶段无关。也就是说分组时认为是相同的key,</div><div>    则在reduce阶段就是在同一个key-values的集合里,因为reduce阶段是将key相同的values集合放在一起,</div><div>    调用一次reducer组件的reduce方法就要将key相同的key-value键值对全部处理完的。</div><div><span style="color: rgb(166, 0, 196);">注意:自定义的排序规则只能是自定义的分组规则的细化。也就是说,如果是按照key中的a和b字段进行分组,</span></div><div><span style="color: rgb(166, 0, 196);">    那么排序只能是: 首先对分好组的key-value数据按a和b进行排序,按照排序规则决定哪</span><span style="color: rgb(255, 0, 0);">组</span><span style="color: rgb(166, 0, 196);">排在前面,哪</span><span style="color: rgb(255, 0, 0);">组</span><span style="color: rgb(166, 0, 196);">排在</span></div><div><span style="color: rgb(166, 0, 196);">    后面</span><span style="color: rgb(255, 0, 0);">(组间排序);</span><span style="color: rgb(166, 0, 196);">然后, 在a和b字段相同的情况下(也就是在同一组的数据),才可以再按照key中的c、d...等进行</span></div><div><span style="color: rgb(166, 0, 196);">    </span><span style="color: rgb(166, 0, 196);">排序</span><span style="color: rgb(255, 0, 0);">(组内排序)</span><span style="color: rgb(166, 0, 196);">(也就是说先排各组之间的先后顺序,</span><span style="color: rgb(166, 0, 196);">再排每组组内各个key-value的顺序)</span></div><div><span style="color: rgb(166, 0, 196);">    也就是如果分组规则是key的a、b,那么排序规则只能是a、b然后c、d(也可以是b、a然后c、d,毕竟分组</span></div><div><span style="color: rgb(166, 0, 196);">    对于是a字段还是b字段优先排序并没有要求,可以根据具体需求改变),而不能是c、d然后a、b,也就是</span></div><div><span style="color: rgb(166, 0, 196);">    说分组规则一定要在前面先排好序,也就是说排序规则一定要先分组,再进行组内排序</span></div><div>    比如说如果分组规则是按照course进行分组,那么排序规则只能制定为先按照course值的不同进行排序,</div><div>    在course相同的情况下再按照score值得不同进行排序。(而不能先按照score进行排序,再按照course进行排序)</div><div>)</div><div><br/></div><div>(2)关于Partitioner</div><div><br/></div><div>对数据进行分区是Partitioner的功能,而分区数reduceTask数和结果文件的数量取决于job.setNumReduceTasks();</div><div>        分区数=ReduceTask数=结果文件数</div><div><br/></div><div>(3)关于combiner</div><div><br/></div><div>combiner是做局部聚合操作,相当于一个小的reducer组件</div><div><br/></div><div><br/></div><div><span style="font-weight: bold;">五、一些跟MapReduce执行流程有关的图(还有一些在: </span><span style="font-weight: bold;">day5-MapReduce基础day1 </span><span style="font-weight: bold;">和 </span><span style="font-weight: bold;">day6-MapReduce基础day2 </span><span style="font-weight: bold;">里面)</span></div><div><br/></div><div><br/></div><div>(1)</div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/mapreduce_shuffle图解11(1).png" type="image/png" data-filename="mapreduce_shuffle图解11(1).png"/></div><div>(2)</div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/mapreduce核心执行流程解析图11.jpg" type="image/jpeg" data-filename="mapreduce核心执行流程解析图11.jpg"/></div><div>(3)</div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/mapreduce架构2.x.jpg" type="image/jpeg" data-filename="mapreduce架构2.x.jpg"/></div><div>(4)</div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/MapReduce核心执行流程图.png" type="image/png" data-filename="MapReduce核心执行流程图.png"/></div><div>(5)</div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/mapreduce流程图.png" type="image/png" data-filename="mapreduce流程图.png"/></div><div>(6)</div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/mapreduce详细执行流程分析.jpg" type="image/jpeg" data-filename="mapreduce详细执行流程分析.jpg"/></div><div><br/></div><div><br/></div><div>(7)</div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/mapreduce执行流程图解.png" type="image/png" data-filename="mapreduce执行流程图解.png"/></div><div>（8）</div><div><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/Image [3].png" type="image/png" data-filename="Image.png"/></div><div><br/></div><div><br/></div><div><br/></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(134, 0, 164); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">——————————————————————</span><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(134, 0, 164); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">—</span><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(134, 0, 164); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">手写与上传资料分割线</span><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(134, 0, 164); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">—</span><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; color: rgb(134, 0, 164); font-family: 微软雅黑; font-variant-caps: normal; font-variant-ligatures: normal; font-weight: bold;">——————————————————————</span></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><br/></span></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><br/></span></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><br/></span></div><div><span style="font-size: medium; letter-spacing: normal; orphans: 2; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"><br/></span></div><div><a href="day14-(1)shuffle详解、MapReduce的执行逻辑_files/hadoop-mr-part5-Shuffle.pdf"><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/da03e60c551060fb8ce08f9679a25983.png" alt="hadoop-mr-part5-Shuffle.pdf"></a></div><div><br/></div><div><br/></div><div><br/></div><div><a href="day14-(1)shuffle详解、MapReduce的执行逻辑_files/hadoop-调优相关常用参数.pdf"><img src="day14-(1)shuffle详解、MapReduce的执行逻辑_files/34eee7524018179f756130545b60e998.png" alt="hadoop-调优相关常用参数.pdf"></a></div><div><br/></div></span>
</div></body></html> 